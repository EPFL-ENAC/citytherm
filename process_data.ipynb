{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97125f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b45a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcz_data = {\n",
    "    'LCZ' : list(range(1, 18)),\n",
    "    'lcz_code': [\n",
    "        'LCZ 1', 'LCZ 2', 'LCZ 3', 'LCZ 4', 'LCZ 5', 'LCZ 6', 'LCZ 7', 'LCZ 8', 'LCZ 9', 'LCZ 10',\n",
    "        'LCZ 11 (A)', 'LCZ 12 (B)', 'LCZ 13 (C)', 'LCZ 14 (D)', 'LCZ 15 (E)', 'LCZ 16 (F)', 'LCZ 17 (G)'\n",
    "    ],\n",
    "    'description': [\n",
    "        'Compact highrise', 'Compact midrise', 'Compact lowrise', 'Open highrise', 'Open midrise',\n",
    "        'Open lowrise', 'Lightweight low-rise', 'Large lowrise', 'Sparsely built', 'Heavy Industry',\n",
    "        'Dense trees', 'Scattered trees', 'Bush, scrub', 'Low plants', 'Bare rock or paved',\n",
    "        'Bare soil or sand', 'Water'\n",
    "    ],\n",
    "    'color': [\n",
    "        '#910613', '#D9081C', '#FF0A22', '#C54F1E', '#FF6628', '#FF985E', '#FDED3F', '#BBBBBB',\n",
    "        '#FFCBAB', '#565656', '#006A18', '#00A926', '#628432', '#B5DA7F', '#000000', '#FCF7B1',\n",
    "        '#656BFA'\n",
    "    ]\n",
    "}\n",
    "\n",
    "lcz_label_df = pd.DataFrame(lcz_data)\n",
    "\n",
    "print(lcz_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grid_data_by_city(grid_path, csv_path, lcz_path, lst_folder, output_dir, id_field='id', exclude_layers=None, lcz_label_df = lcz_label_df):\n",
    "    \"\"\"\n",
    "    Process grid data from a GeoPackage and CSV for multiple layers,\n",
    "    creating separate GeoJSON files for each city.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    grid_path : str\n",
    "        Path to the GeoPackage file containing the grid layers\n",
    "    csv_path : str\n",
    "        Path to the CSV file containing data associated with each grid ID\n",
    "    output_dir : str\n",
    "        Directory where the output GeoJSON files will be saved\n",
    "    id_field : str\n",
    "        The field name used to join the datasets\n",
    "    exclude_layers : list, optional\n",
    "        List of layer names to exclude from processing\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize exclude_layers as empty list if None\n",
    "    if exclude_layers is None:\n",
    "        exclude_layers = []\n",
    "    \n",
    "    # Get all available layers\n",
    "    available_layers = fiona.listlayers(grid_path)\n",
    "    \n",
    "    # Filter out excluded layers\n",
    "    available_layers = [layer for layer in available_layers if layer not in exclude_layers]\n",
    "    \n",
    "    lcz_df = pd.read_csv(lcz_path)\n",
    "    lcz_df = lcz_df[[id_field, 'City', 'LCZ']].copy()\n",
    "    lcz_df = lcz_df.merge(lcz_label_df, left_on='LCZ', right_on='LCZ', how='left')\n",
    "\n",
    "    # Read the CSV data once\n",
    "    full_data_df = pd.read_csv(csv_path)\n",
    "    full_data_df = full_data_df.merge(lcz_df, on=[id_field, 'City'], how='left')\n",
    "    \n",
    "    # Group layers by city\n",
    "    geneva_layers = []\n",
    "    zurich_layers = []\n",
    "    \n",
    "    for layer in available_layers:\n",
    "        # Normalize layer name to lowercase for comparison\n",
    "        layer_lower = layer.lower()\n",
    "        if 'geneva' in layer_lower:\n",
    "            geneva_layers.append(layer)\n",
    "        elif 'zurich' in layer_lower:\n",
    "            zurich_layers.append(layer)\n",
    "    \n",
    "    # Process Geneva layers\n",
    "    if geneva_layers:\n",
    "        # Filter CSV data for Geneva only\n",
    "        geneva_data_df = full_data_df[full_data_df['City'].str.lower() == 'geneva'].copy()\n",
    "        print(f\"Filtered {len(geneva_data_df)} Geneva records from CSV data\")\n",
    "        \n",
    "        process_city_layers(grid_path, geneva_data_df, lst_folder, geneva_layers, \n",
    "                           os.path.join(output_dir, \"geneva_grid_data.geojson\"), \n",
    "                           id_field, city_suffix=\"geneva\")\n",
    "    \n",
    "    # Process Zurich layers\n",
    "    if zurich_layers:\n",
    "        # Filter CSV data for Zurich only\n",
    "        zurich_data_df = full_data_df[full_data_df['City'].str.lower() == 'zurich'].copy()\n",
    "        print(f\"Filtered {len(zurich_data_df)} Zurich records from CSV data\")\n",
    "\n",
    "        process_city_layers(grid_path, zurich_data_df, lst_folder, zurich_layers,\n",
    "                           os.path.join(output_dir, \"zurich_grid_data.geojson\"),\n",
    "                           id_field, city_suffix=\"zurich\")\n",
    "    \n",
    "    return geneva_layers, zurich_layers\n",
    "\n",
    "def clean_layer_name(layer_name, city_suffix):\n",
    "    \"\"\"\n",
    "    Extract the base layer name without city suffixes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    layer_name : str\n",
    "        Original layer name from GeoPackage\n",
    "    city_suffix : str\n",
    "        City suffix to remove (e.g., 'geneva', 'zurich')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Cleaned layer name without city-specific parts\n",
    "    \"\"\"\n",
    "    # Convert to lowercase for case-insensitive matching\n",
    "    layer_lower = layer_name.lower()\n",
    "    city_suffix = city_suffix.lower()\n",
    "    \n",
    "    # Remove common prefixes or suffixes\n",
    "    cleaned_name = layer_name\n",
    "    \n",
    "    # Pattern 1: Remove \"_cityname\"\n",
    "    cleaned_name = re.sub(f\"_{city_suffix}\", \"\", cleaned_name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Pattern 2: Remove \"-cityname\"\n",
    "    cleaned_name = re.sub(f\"-{city_suffix}\", \"\", cleaned_name, flags=re.IGNORECASE)\n",
    "\n",
    "    return cleaned_name\n",
    "\n",
    "def calculate_lst_averages(grid_gdf, lst_folder, city_name):\n",
    "    \"\"\"\n",
    "    Calculate average LST values for each grid cell from multiple GeoTIFF files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    grid_gdf : GeoDataFrame\n",
    "        GeoDataFrame containing grid cells\n",
    "    lst_folder : str or Path\n",
    "        Path to folder containing LST GeoTIFF files\n",
    "    city_name : str\n",
    "        Name of the city to process (geneva or zurich)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    GeoDataFrame\n",
    "        Input GeoDataFrame with new 'lst_mean' column\n",
    "    \"\"\"\n",
    "    lst_folder = Path(lst_folder)\n",
    "    # Find all GeoTIFF files for this city\n",
    "    lst_files = list(lst_folder.glob(f\"*{city_name}*.tif\"))\n",
    "    \n",
    "    if not lst_files:\n",
    "        print(f\"No LST files found for {city_name} in {lst_folder}\")\n",
    "        return grid_gdf\n",
    "    \n",
    "    print(f\"Processing {len(lst_files)} LST files for {city_name}\")\n",
    "    \n",
    "    # Initialize array to store LST values for each cell\n",
    "    all_lst_values = []\n",
    "\n",
    "    # Process each LST file\n",
    "    for lst_file in lst_files:\n",
    "        print(f\"  Processing {lst_file.name}\")\n",
    "        with rasterio.open(lst_file) as src:\n",
    "            # Calculate zonal statistics for each grid cell\n",
    "            stats = zonal_stats(\n",
    "                grid_gdf.geometry,\n",
    "                src.read(1),  # Read first band\n",
    "                affine=src.transform,\n",
    "                stats=['mean'],\n",
    "                nodata=src.nodata\n",
    "            )\n",
    "            \n",
    "            # Extract mean values and handle None values\n",
    "            means = []\n",
    "            for stat in stats:\n",
    "                if stat is not None and 'mean' in stat and stat['mean'] is not None:\n",
    "                    means.append(float(stat['mean']))\n",
    "                else:\n",
    "                    means.append(np.nan)\n",
    "            all_lst_values.append(means)\n",
    "\n",
    "    # Convert to numpy array and calculate mean\n",
    "    lst_array = np.array(all_lst_values, dtype=float)\n",
    "    lst_means = np.nanmean(lst_array, axis=0)\n",
    "    \n",
    "    # Add to GeoDataFrame\n",
    "    grid_gdf = grid_gdf.copy()\n",
    "    grid_gdf['lst_mean'] = lst_means\n",
    "\n",
    "    return grid_gdf\n",
    "\n",
    "def process_city_layers(grid_path, data_df, lst_folder, layers, output_path, id_field, city_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Process and merge multiple layers for a city into a single GeoJSON with one feature per grid cell.\n",
    "    Dynamically uses the spatial join keys that are present in each layer.\n",
    "    \"\"\"\n",
    "    print(f\"Processing layers for {os.path.basename(output_path)}:\")\n",
    "    \n",
    "    # All potential spatial properties to use for merging layers\n",
    "    all_spatial_join_keys = ['id', 'left', 'top', 'right', 'bottom', 'row_index', 'col_index', 'geometry', 'typology']\n",
    "    \n",
    "    # Dictionary to store each layer's GeoDataFrame\n",
    "    layer_gdfs = {}\n",
    "    \n",
    "    # Track the CRS for consistent projection\n",
    "    common_crs = None\n",
    "    \n",
    "    # First, read all layers\n",
    "    for layer in layers:\n",
    "        print(f\"  - Reading layer: {layer}\")\n",
    "        try:\n",
    "            # Read the layer\n",
    "            layer_gdf = gpd.read_file(grid_path, layer=layer)\n",
    "            \n",
    "            # Store CRS for later use\n",
    "            if common_crs is None:\n",
    "                common_crs = layer_gdf.crs\n",
    "                \n",
    "            # Clean the layer name to remove city suffix\n",
    "            clean_name = clean_layer_name(layer, city_suffix)\n",
    "            \n",
    "            # Identify which spatial join keys are present in this layer\n",
    "            available_keys = [key for key in all_spatial_join_keys if key in layer_gdf.columns]\n",
    "            \n",
    "            # Store the available keys with the layer\n",
    "            layer_info = {\n",
    "                'gdf': layer_gdf,\n",
    "                'available_keys': available_keys\n",
    "            }\n",
    "            \n",
    "            # Store in dictionary\n",
    "            layer_gdfs[clean_name] = layer_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing layer {layer}: {str(e)}\")\n",
    "    \n",
    "    # If no layers were read successfully, return\n",
    "    if not layer_gdfs:\n",
    "        print(f\"No layers could be processed for {os.path.basename(output_path)}\")\n",
    "        return\n",
    "    \n",
    "    # Start with the first layer as our base\n",
    "    base_layer_name = list(layer_gdfs.keys())[0]\n",
    "    combined_gdf = layer_gdfs[base_layer_name]['gdf'].copy()\n",
    "    \n",
    "    # Merge remaining layers one by one\n",
    "    for layer_name, layer_info in list(layer_gdfs.items())[1:]:\n",
    "        print(f\"  - Merging layer: {layer_name}\")\n",
    "        \n",
    "        # Get the layer GeoDataFrame\n",
    "        layer_gdf = layer_info['gdf']\n",
    "        \n",
    "        # Determine which keys to use for merging with this layer\n",
    "        # Find keys that exist in both the combined data and this layer\n",
    "        available_keys = layer_info['available_keys']\n",
    "        merge_keys = [key for key in available_keys if key in combined_gdf.columns]\n",
    "        \n",
    "        # Ensure we have at least some keys for joining, including 'geometry'\n",
    "        if 'geometry' not in merge_keys:\n",
    "            merge_keys.append('geometry')\n",
    "        \n",
    "        print(f\"    Using merge keys: {merge_keys}\")\n",
    "        \n",
    "        # Use outer join to keep all features\n",
    "        combined_gdf = combined_gdf.merge(\n",
    "            layer_gdf,\n",
    "            on=merge_keys,\n",
    "            how='outer'\n",
    "        )\n",
    "    \n",
    "    # Add a column to track which city this is\n",
    "    combined_gdf['City'] = city_suffix.lower()\n",
    "    \n",
    "    # Now join with the CSV data on id_field\n",
    "    if id_field in combined_gdf.columns:\n",
    "        print(f\"  - Joining with CSV data on field: {id_field}\")\n",
    "        combined_gdf = combined_gdf.merge(data_df, on=id_field, how='left')\n",
    "    else:\n",
    "        print(f\"  Warning: Combined data does not contain id_field '{id_field}', skipping CSV join\")\n",
    "    \n",
    "    # Add LST data if available\n",
    "    if os.path.exists(lst_folder):\n",
    "        print(f\"  - Calculating LST averages\")\n",
    "        combined_gdf = calculate_lst_averages(combined_gdf, lst_folder, city_suffix)\n",
    "    \n",
    "\n",
    "    # Export to GeoJSON\n",
    "    combined_gdf.to_file(output_path, driver=\"GeoJSON\")\n",
    "    print(f\"Exported {len(combined_gdf)} unique grid cells to {output_path}\")\n",
    "    \n",
    "    return combined_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f42d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "data_folder = os.getenv('CITYTHERM_DATA_FOLDER', str(Path.home() / \"Data\"))\n",
    "grid_path = os.path.join(data_folder, \"open data multidomain neighbourhood types and environmental quality.gpkg\")\n",
    "csv_path = os.path.join(data_folder, \"open_data_neighbourhood_parameters.csv\")\n",
    "output_path = os.path.join(data_folder, \"grid_data.geojson\")\n",
    "lcz_path = os.path.join(data_folder, \"citytherm.csv\")\n",
    "lst_folder = os.path.join(data_folder, \"lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = os.path.join(data_folder, \"processed\")\n",
    "\n",
    "# Process all layers by city\n",
    "geneva_layers, zurich_layers = process_grid_data_by_city(\n",
    "    grid_path=grid_path,\n",
    "    csv_path=csv_path,\n",
    "    lcz_path=lcz_path,\n",
    "    lst_folder=lst_folder,\n",
    "    output_dir=output_dir,\n",
    "    id_field='id',\n",
    "    exclude_layers=[\"LST-Geneva\"]  # Exclude problematic layer\n",
    ")\n",
    "\n",
    "print(\"\\nProcessed Geneva layers:\")\n",
    "for layer in geneva_layers:\n",
    "    print(f\"- {layer}\")\n",
    "\n",
    "print(\"\\nProcessed Zurich layers:\")\n",
    "for layer in zurich_layers:\n",
    "    print(f\"- {layer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citytherm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
